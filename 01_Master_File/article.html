<!--
  Copyright 2018 The Distill Template Authors

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!doctype html>

<head>
  <script src="https://distill.pub/template.v2.js"></script>
  <script src='https://d3js.org/d3.v4.min.js' charset="utf-8"></script>
<!--   <script src="https://d3js.org/d3-selection-multi.v0.4.min.js"></script> -->

<script>
  function MathCache(id) {
    return document.querySelector("#math-cache ." + id).innerHTML;
  }
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1" >
  <meta charset="utf8">
  <link href="style.css" rel="stylesheet" type="text/css">
</head>
<body>
  <distill-header></distill-header>
<d-front-matter>
  <script id='distill-front-matter' type="text/json">{
    "title": "The Physics behind Energy-Based Models",
    "description": "We need to understand the simple models",
    "published": "XXX xx, 2019",
    "authors": [
      {
        "author":"Patrick Huembeli",
        "authorURL":"http://patrickhuembeli.github.io/",
        "affiliations": [{"name": "ICFO-The Institute for Photonics", "url": "https://icfo.eu/"}]
      },
      {
        "author":"Juan-Miguel Arrazola",
        "affiliations": [{"name": "Xanadu", "url": "https://www.xanadu.ai/"}]
      },
      {
        "author":"Nathan Killoran",
        "authorURL":"https://github.com/co9olguy",
        "affiliations": [{"name": "Xanadu", "url": "https://www.xanadu.ai/"}]
      },
      {
        "author":"Peter Wittek",
        "authorURL":"https://peterwittek.com/",
        "affiliations": [
          {"name": "University of Toronto", "url": "https://www.rotman.utoronto.ca/"},
          {"name": "Creative Destruction Lab", "url": "https://www.creativedestructionlab.com/"},
          {"name": "Vector Institute for Artificial Intelligence", "url": "https://vectorinstitute.ai/"},
          {"name": "Perimeter Institute for Theoretical Physics", "url": "https://perimeterinstitute.ca/"}
        ]
      }
    ],
    "katex": {
      "delimiters": [
        {"left": "$$", "right": "$$", "display": false}
      ]
    }
  }</script>
</d-front-matter>
<!-- Put Title, short abstract and image -->
<d-title>
<!--   <figure style="grid-column: page; margin: 1rem 0;"><img src="momentum.png" style="width:100%; border: 1px solid rgba(0, 0, 0, 0.2);"/></figure> -->

    <figure style = "grid-column: page; margin: 1rem 0;" id = "RBM_Graph">
  <div id = "RBM_graph_id" style="left:0px; top:0px"></div>
  </figure>

  <script type = "text/javascript" src = "figures/RBM2_script.js" ></script>
  <p>Taking a closer look at the physics of energy-based models sparks new insights on the future of these architectures</p>
</d-title>
<d-byline></d-byline>
<!-- Actual Article starts here -->
<d-article>
<!--  INTRODUCTION -->
  <a class="marker" href="#section-1" id="section-1"><span>Introduction</span></a>

  <p>
  In the 1980s, graphical models were extensively studied <b>PW: It was Judea Pearl who came up with graphical models in the 1980s -- this is more of the Bayesian/Markovian network stuff, but it might be worth referencing. He might have had a book by the late 1980s on this</b>.
  A subset of these models are called energy-based models, which have properties familiar from the theory of neural networks, but they are also grounded in statistical mechanics <b>PW: a reference or two wouldn't hurt</b>, which is a branch of modern physics.
  In this article, we will walk you through the dynamics of the most important energy-based models – Hopfield networks and Boltzmann machines – reflecting on the meaning of the underlying concepts in computer science and physics.
  Additionally, we will provide a new way of interpreting training from the perspective of thermal equilibration and review the differences between learning and memorizing in this perspective.
  </p>

  <p>
  Energy-based models emerged in the machine learning literature in the 1980s.
	Essentially, machine learning researchers &ldquo;ported&rdquo; certain ideas which were originally developed for statistical physics. In particular, the idea that the probability for a system to be in a particular configuration   <d-math>x</d-math> can be specified using a single scalar function – the <em>energy</em> <d-math>E(x)</d-math> – of that configuration.</p>

  <p>These models were further developed, extended, and improved, over several decades. Currently, the hottest topic in machine learning is deep neural networks trained by backpropagation: energy-based models have fallen somewhat out of favour amongst practitioners. Despite this, some energy-based models, Boltzmann machines especially, have recently been “back-ported” to physics, where they have successfully been used to model the wavefunctions of quantum systems <d-cite key="carleo2017solving"></d-cite>. They also seem to get back into the focus of fundamental research in machine learning. <d-footnote>According to this <a href="https://twitter.com/datasciencenig/status/1020355546581553152" target="_blank">tweet</a>, Yoshua Bengio as an example wants to return to studying Boltzmann machines for a better understanding of generative models.</d-footnote> Furthermore Boltzmann machines are still being used in other areas, such as recommendation systems <d-cite key='salakhutdinov_restricted_2007'></d-cite><b>PW: We could also cite https://openai.com/blog/energy-based-models/</b> The rekindled interest is understandable: many types of energy-based models are generative, guarantee to sample a valid probability distribution, and they can often be stacked to create deep, hierarchical representations <b>PW: Cite the deep belief network paper</b>.</p>

  <p>In the first part of this article we introduce the framework of energy-based models, alternating between a computer science view and a physics perspective, and introduce the most common architectures.
  Most of the models are probabilistic, so we also take a closer look at sampling the distributions they model.
  In the second part of the article, we will describe the training procedure in detail, introducing a new interpretation of the procedure coming from physics principles.</p>

<!-- Second Section  2  -->
  <a class="marker" href="#section-2" id="section-2"><span>Energy-based models</span></a>
  <h2 id="testing-the-bm-as-a-trained-model">Energy-based models</h2>

  Energy-based models rely on the principle of maximum entropy. From the principle of maximum entropy one obtains the Boltzmann distribution that describes a system at thermal equilibrium at finite temperature.
  The nature of this system will be defined by the choice of the constraints under which we want to maximise the entropy and the sufficiency of their statistics.
  We will have a brief discussion about energy-based models and the connection of energy and probability which will lead us to the first concrete machine learning model, the Hopfield network. We will draw the connection of the sampling procedure of these models and how physical system equilibrate. The introduction of hidden and visible units will finally lead us to the Boltzmann machine. We will emphasise why the use of hidden units is beneficial for machine learning purposes, but also what it physically means. And finally we will emphasise the importance of the introduction of a bipartition of the graph of the Boltzmann machine, which is commonly known as a restricted Boltzmann machine.

<!-- Second Section  2.1  -->
  <a class="marker" href="#section-2.1" id="section-2.1"><span>Maximum Entropy</span></a>
  <h3 id="the-principle-of-maximum-entropy">The principle of maximum entropy</h3>
  <p>The <em>principle of maximum entropy</em>, tells us that, amongst all distributions which are consistent with known observations (e.g., the expectation values of certain random variables), the distribution with maximal entropy should be preferred. Known observations in machine learning are for example the statistics of single input pixels or the correlations between pixels of the data.</p>

  <p>Intuitively, it makes sense to choose the distribution with maximum entropy. If we do not have any information – and therefore no constraint – about a particular degree of freedom of a system, we should remain maximally flexible in our choice of model, while remaining consistent with the degrees of freedom that are constrained. Choosing the maximum entropy model reduces the amount of potentially biased or unsubstantiated prior information built into a model.
  </p>

  <p>Suppose we have a system which can exist in many different possible configurations <d-math>\{\vec{x}_j\}_{j=1}^J</d-math>; the elements of these vectors are random variables. We assume a discrete set of configurations, but similar arguments can be made for a continuous set. We have some partial information about the system, specifically, the expectation values of functions <d-math>r_k</d-math> of the random variables <d-math>\{r_k(\vec{x})\}_{k=1}^K</d-math>. These can be constraints forced upon the system by us or actually observed in the data. That is, we have the constraints on the expectation values<d-math block>  \langle r_k \rangle_{x} = a_k, </d-math> with <d-math>\langle r_k \rangle_{x} = \sum_i p(\vec{x}_i) r_k(\vec{x}_i). </d-math>
  These expectation values are not sufficient to completely characterize the system (i.e. if we have more configurations than constraints, <d-math>J>K </d-math>), and we have no information about random variables outside of the span of the <d-math>r_k </d-math>. The principle of maximum entropy tells us that, if we want to model this system, we should maximize the entropy <d-math>H(x) = -\sum_{j=1}^J p(\vec{x}_j) \log p(\vec{x}_j) </d-math>, subject to the given constraints, plus we need to take care that the probabilities are normalized <d-math>\sum_{j=1}^J p(\vec{x}_j) = 1 </d-math>. Thus, we want to solve a constrained optimization problem. Instead, we apply using Lagrange multipliers <d-math>\lambda_i</d-math> for the constraints to make the maximization unconstrained, arriving at the following optimization problem:
  <d-math block> \text{max}_{\lambda_i}[-\sum_{j=1}^J p(\vec{x}_j) \log p(\vec{x}_j) + \sum_{k=1}^K \lambda_k (\langle r_k \rangle_{\vec{x}_j} - a_k) + \lambda_0(\sum_{j=1}^J p(\vec{x}_j) - 1)], </d-math>
  which has the solution<d-footnote>To derive the connection, we recommend Leonard Susskind's <a href="https://youtu.be/SmmGDn8OnTA?t=1959">lecture</a> from around minute 32, where he gives a simple derivation of the Boltzmann distribution of a system at a fixed energy <d-math>E</d-math> </d-footnote>
  <d-math block>p(\vec{x}_j) = \frac{1}{Z} \exp \left( \sum_k^K \lambda_k  r_k (\vec{x}_j)\right).
  </d-math>
  This probability distribution is known under the name Boltzmann distribution.</p>

<!-- Second Section  2.2  -->
  <a class="marker" href="#section-2.2" id="section-2.2"><span>Boltzmann distribution and equilibrium</span></a>
  <h3 id="boltzmann-distribution-and-equilibrium">Boltzmann distribution and equilibrium</h3>

  <p>The Boltzmann distribution is known from physics and it describes the statistics of physical configurations of a system that is in an equilibrium at some temperature.
  In this case the probability of a configuration <d-math>\vec{x}</d-math> is given as <d-math>p(\vec{x}) = 1/Z \exp (- 1/T \cdot E(\vec{x}) )</d-math>.
  Where <d-math>E(\vec{x})</d-math> is a function that connects the configuration <d-math>\vec{x}</d-math> with the real line, which is also called the energy of the system. Before, we did not explicitely write the temperature because we either set it to <d-math>T=1</d-math> or it is already absorbed in the Lagrange parameters <d-math>\lambda_k</d-math> of the model. But it is important that we are looking at systems with non-zero temperature because for zero temperature a physical system will equilibrate to a local minimum.
  Allowing a non-zero temperature automatically leads to states that are in a thermal distribution which means the system can be in configurations that are at low energy and not only minimum energy. Low-energy configurations are more likely than high-energy configurations, and if two configurations have the same energy, they are equally likely. The Boltzmann distribution connects energy to probability via the above formula. In the extreme case of very high temperature all the configurations even get equally likely.</p>

<!-- Figure Section 2.2  -->
  <div class="row">
  <div class="column">
  <p class="slider-label-text">Temperature: </p>
  <p id="temperature_slider" class="slider-label-number"></p>
    <input id="temp_slider_id" type="range" oninput="temp_slider(this.value)" min="0.001" max="1" step="0.001">
    <p class="slider-label-text">Energy Gap: </p>
    <p id="energy_slider" class="slider-label-number" width="100%"></p>
    <input type="range" oninput="energy_slider(this.value)" min="0" max="10" step="0.01">
    <p class="figure-text">2-level system with temperature. This is a simple model that shows the influence of temperature on the probability to be in a certain state. If the system is at zero temperature only the low energy state can be occupied. If the temperature is increased the higher energy level can also be occupied. If we are at very high temperature, both states get equally likely. </p>
  </div>
  <div class="doublecolumn">
    <p class="slider-label-text">Unnormalized Probability </p>
    <figure style = "width:100%; height:280px; display:block; margin-left:auto; margin-right:auto; position:relative" id = "RBM_complete">
  <div id = "test_figure_id" style="position:absolute; left:0px; top:0px"></div>
  </figure>
  <script type = "text/javascript" src = "2-level-sys_new.js" ></script>
  </div>
  </div>
  <div class="triplecolumn"> <p class="figure-text">This figure shows the effect of temperature on the occupation probability of a higher energy state. If the energy difference between the sates is big and the temperature is low, the probability of the system to be in the higher energy state goes to zero. On the other side if the temperature increases or the energy gap closes the system gets more likely to be in the higher energy state.<p></div>

  <p> Temperature in the end will make the difference between a simple memory and actual learning where the model is able to generalize the learned data and ouput new configurations that are close to the training data. The intuition here is the following: Memorizing means that each configuration of the training set will be in a local minimum of the energy landscape. Therefore any configuration that is not at a local minimum will equilibrate to the next minimum and we will retrieve the exact training examples.
  If the temperature is non-zero, configurations that are not exactly at a local minimum of the energy landscape can occur with some probability. The higher the temperature the more likely these higher-energy states get. The configurations around one local energy minimum can occur and if the temperature is not to high the possible configurations are all similar.</p>

<!-- Second Section  2.3  -->
  <a class="marker" href="#section-2.3" id="section-2.3"><span>From the sufficient statistics to the energy function</span></a>
  <h3 id="from-the-sufficient-statistics-to-the-energy-function">From the sufficient statistics to the energy function</h3>
  <p>So far this result is general and can be applied to any constraint. The choice of <d-math>\langle r_k \rangle_x</d-math>, or, equivalently, the choice of the energy function <d-math>E(\vec{x})</d-math>, will define the physics of the model. The most commonly used physical model in machine learning is a so-called <em>Ising model</em>, which is defined through a energy function <d-math>E(\vec {\sigma}) = \sum_{i,j} w_{i,j} \sigma_i \sigma_j + \sum_i h_i \sigma_i</d-math>.
  Here we used a physics convention: the discrete configurations <d-math>\vec{x}</d-math> are representation by "spins" <d-math>\vec {\sigma}</d-math>, which are just binary random variables taking values <d-math>+1</d-math> or <d-math>-1</d-math>.
  We can always easily convert between spins and binary random variables taking values <d-math>0</d-math> or <d-math>1</d-math>, or any other discrete variables.
  To recover a Boltzmann distribution with this energy function, we rename the Lagrange multipliers <d-math>\lambda_k </d-math> to <d-math>w_{i,j} </d-math> which are the couplings and <d-math>h_i </d-math> which are the local magnetic fields.
  The sufficient statistic of the Boltzmann distribution of such an Ising model are the single-spin expectation values <d-math>\langle \sigma_i \rangle</d-math> and the two-spin correlations <d-math>\langle \sigma_i \sigma_j \rangle</d-math>.

  <d-footnote>Generally for the exponential family, a statistic <d-math>T(\vec{x})</d-math> is sufficient, if we can write the probability <d-math>p(\vec{x})</d-math> as
  <d-math block>p(\vec{x}) = \exp \left( \alpha(\theta)^T T(\vec{x}) + A(\theta) \right),</d-math>
  where <d-math>\alpha(\theta)</d-math> is a vector valued function and <d-math>A(\theta)</d-math> is a scalar which for a Boltzmann distribution is simply a normalization factor that we call the partition function <d-math>A(\theta) = \log(1/Z)</d-math> <d-cite key="li_learning_2013"></d-cite>. Therefore in general we are not restricted to model the distribution of our data with the energy function of a classical Ising model. The choice of the constraints will determine the physical model.
  </d-footnote>

  This means that these two constraints suffice to fully determine the Lagrange parameters of the classical Ising energy function from the data.
  Therefore we set the constraints to <d-math>\langle r_k \rangle = \langle \sigma_i \sigma_j\rangle</d-math> and <d-math>\langle r_k \rangle = \langle \sigma_i \rangle</d-math>.

  We want to emphasise at this point that for real world machine learning applications higher-order correlations between input nodes are important and the choice of single-spin and two-spin expectation values in general is not sufficient to capture them. So far this model is simply an Ising spin system, where every spin represents a node (e.g. pixel) of our input data. To overcome this issue of low order correlations we will later use a part of the spins in the system as mediators between input nodes, which we we call hidden units.</p>
  <p><b> This is only a test cite</b>We can<d-cite key="mercier2011humans"></d-cite> also cite <d-cite key="gregor2015draw,mercier2011humans"></d-cite>
<!-- Second Section  2.4  -->
  <a class="marker" href="#section-2.4" id="section-2.4"><span>Architectures</span></a>
  <h3 id="architecture">Architectures</h3>
  <p>So far we have not restricted ourselves to a certain kind of model. But for practical purposes some models have been proven to be more useful than others and the most common models are based on the energy function of a Ising spin system. The first model we introduce is the Hopfield network, which is simply an Ising model of <d-math>N</d-math> spins at zero temperature, where the dimension of the data vector is equal to the number of available spins. This kind of model does not really learn configurations, it just memorizes them.</p>

  <p>The Boltzmann machine is different from the Hopfield network in two aspect. First, it is not at zero temperature anymore, therefore we allow thermal distributions of configurations and not only local minima of the energy. Second, the <d-math>N</d-math> spins of the model are separate into <d-math>v</d-math> visible units (in blue) and <d-math>h</d-math> hidden units (in yellow). The dimension of the input data is equal to the visible units <d-math>v</d-math>. The choice of the Boltzmann machine as an ansatz for the probability distribution in machine learning is very well motivated by its success in experiments (Cite some RBM papers), but for a physicist intuitively the question comes to mind: why shouldn't we use any other energy function that we know from physics? It might be more expressive. When we approach energy-based models from the principle of maximum entropy we can see that the constraints and therefore the data itself determines the model. Therefore, from a theoretical point of view, we are not restricted to Ising-like energy functions. It is even known that single-spin expectation values and two-spin correlators are in general not sufficient to learn complex data, such as images. This issue is overcome by adding hidden units that are not expressing data instances. They are used to mediate between visible units and they are averaged out in the end.</p>

  <p>Finally, the restricted Boltzmann machine (RBM) is the model that is most commonly used. Avoiding connections within the same layer brings an advantage to compute the gradients during training (see Section <b>Insert ref.</b>). Compared to the fully conected Boltzmann machine the RBM has less expressivity as there are much fewer parameters. On the other hand, following the principles of statistical learning theory and Occam's razor, less complex models tend to generalize better if their training error is comparable to a more complex model (CITE https://arxiv.org/pdf/1706.08947.pdf), since complex models are more likely to overfit the data.</p>

  <div class="row">
  <div class="column">
    <p class="figure-text">Hopfield network: The number of nodes is equal to the size of the input data. There are no hidden nodes (dashed) contributing to the energy.</p>
    <figure style = "width:100%; height:280px; display:block; margin-left:auto; margin-right:auto; position:relative" id = "architecture_Hopfield">
  <div id = "architecture_Hopfield_id" style="position:absolute; left:0px; top:0px"></div>
  </figure>
  </div>
  <div class="column">
    <p class="figure-text">Boltzmann machine: The Boltzmann machine graph is fully connected. The visible nodes (blue) are clamped to the input data. The hidden nodes (yellow) are free parameters.</p>
    <figure style = "width:100%; height:280px; display:block; margin-left:auto; margin-right:auto; position:relative" id = "architecture_BM">
  <div id = "architecture_BM_id" style="position:absolute; left:0px; top:0px"></div>
  </figure>
  </div>
  <div class="column">
    <p class="figure-text">Restricted Boltzmann machine: Also with hidden and visible nodes, but we don't allow connections within the same layer. This will simplify the training.
    <figure style = "width:100%; height:280px; display:block; margin-left:auto; margin-right:auto; position:relative" id = "architecture_RBM">
  <div id = "architecture_RBM_id" style="position:absolute; left:0px; top:0px"></div>
  </figure>
  </div>
  </div>
  <script type = "text/javascript" src = "architecture.js" ></script>

<!-- Second Section  3  -->
  <a class="marker" href="#section-3" id="section-3"><span>Sampling</span></a>
  <h2 id="sampling">Sampling</h2>
  <p>A model with a fixed energy function will assign an energy to every configuration and configurations with low energies will be more likely to appear. Sampling from a model is the ability to recover low energy configurations from a system with a given energy function. As we will see the process of sampling on a real physical system in a laboratory is somewhat very simple and occurs naturally, if such a system can be implemented in a laboratory. On the other side sampling is notoriously difficult in computer simulations</p>

  <div class="row">

  <div class="triplecolumn">
    <figure style = "width:100%; height:500px; display:block; margin-left:auto; margin-right:auto; position:relative" id = "architecture_Hopfield">
  <div id = "image_equilibration_id" style="position:absolute; left:0px; top:0px"></div>
  </figure>
  </div>
  <div class="triplecolumn">
	  <p class="figure-text"> One  <input id="equilibrate_button_id" type="button" value="Equilibration step" onclick="equilibration_step_rbm()"> brings the damaged initial configuration closer to a low energy configuration. The hidden and the visible layers are updated one after another. </p><p class="figure-text"><b>Sampling through equilibration:</b> This figure shows a restricted Boltzmann machine, where the visible units are initialized with a partially damaged MNIST digit and the hidden units are initiallized all in the same direction. In an RBM, the equilibration is sequentially, where the hidden and the visible layer is sampled one after another dependend of the configuration of the other layer. The energy during the equilibration process will go to a lower value.</p>
  </div>
  </div>
  <script type = "text/javascript" src = "image_equilibration_script.js" ></script>

  <div class="triplecolumn"></div>

<!-- Second Section  3.1  -->
  <a class="marker" href="#section-3.1" id="section-3.1"><span>Sampling in physics</span></a>
  <h3 id="sampling-in-physics">Sampling in physics</h3>
  <p>We would like to think of energy-based models the following way. Imagine you are an experimentor and you have an implementation of a spin system in front of you. You can initialize the spins and you can manipulate the couplings <d-math>J_{i,j}</d-math> and the local fields <d-math>h_i</d-math>. The only thing you can do with such a machine is to initialize the spins in some way and see what configuration they will equilibrate to. In physics, low energies are preferred over high energies. And therefore if we initialize a system randomly it will eventually equilibrate to a low energy configuration, or, if we are at <d-math>T=0</d-math>, to a local minimum of the energy. Therefore in a real physical system, sampling from a system is only a matter of initialising it and waiting until it equilibrates.</p>

  <div class="row">
    <div class="column">
    <p class="figure-text"><b>Influence of Temperature on Configurations: </b>After training local energy minima correspond to configurations of the training set. At zero temperature configurations with higher energy will equilibrate to the minimum energy configuration. For non zero temperature higher energy configurations can be occupied with a certain probability here shown as a shaded blue area around the minima.</p>
    </div>
    <div class="doublecolumn">
      <p class="slider-label-text">Energy Minima </p>
      <figure style = "width:100%; height:280px; display:block; margin-left:auto; margin-right:auto; position:relative" id = "Figure_energy_minima_and_temp">
    <div id = "energy_minima_and_temp_id" style="position:absolute; left:0px; top:0px"></div>
    </figure>
    <script type = "text/javascript" src = "energy_minima_and_temp.js" ></script>
    </div>
  </div>
  <div class="triplecolumn"><p class="figure-text"> This figure illustrates two local energy minima that contain a different MNIST number as their minimum energy. If we are at zero temperature any higher energy configuration would equilibrate to the closest local minimum and the only configurations that can be retrieved are the ones at the minimum energy. If we allow a certain temperature (blue shaded area) we can also retrieve configurations with a slightly higher energy. This eventually makes the system to generalize training data.</p></div>


<!-- Second Section  3.2  -->
  <a class="marker" href="#section-3.2" id="section-3.2"><span>Sampling in machine learning</span></a>
  <h3 id="sampling-in-ml">Sampling in machine learning</h3>

  <p>In machine learning, we do not have an equilibration process that drives our system into a low energy configuration. We therefore have to simulate this process. But there are several methods how we can imitate this behaviour. To sample from a Hopfield network, we samplet The Boltzmann distribution at zero temperature: the lowest energy is always occupied with 100% probability. Therefore in a potential well, equilibration can only go into the direction of lower energy. Therefore to find a rule of equilibration at zero temperature for a single spin <d-math>\sigma_i</d-math>
  we only have to find out which local spin direction is favourable.
  For the given Ising energy function <d-footnote> <d-math>E(\vec {\sigma}) = \sum_{i,j} w_{i,j} \sigma_i \sigma_j + \sum_i h_i \sigma_i</d-math></d-footnote>, if
  <d-math block> E(\sigma_i=-1) - E(\sigma_i=+1)  \geq 0</d-math>

  we set the local spin to <d-math>+1</d-math>. From this we get the simple local update rule.

  <d-math block>\sigma_{i}\leftarrow \left\{{\begin{array}{ll}+1~{\text{if }}-\sum _{{j}}{w_{{ij}}\sigma_{j}}\geq h _{i},\\-1~{\text{otherwise,}}\end{array}}\right.</d-math>

  We can update the configuration spin after spin according to this rule and converge to a local minimum. (CITE Paper)
  The outcome in this case is deterministic and one can stop this process after the nodes have been iterated through two times without any update.
  </p>

  <p>For finite temperature we still compare the energy difference when one spin is changed
  <d-math>\Delta E =  E(\sigma_i) - E(-\sigma_i)</d-math>, but now there is a probability to change the configuration even though the energy is increased by this step. The update rule is expanded the following way: If a change of the spin decreases the energy <d-math>\Delta E \geq 0</d-math> the spin will be changed and we update to <d-math>\sigma_i \leftarrow -\sigma_i</d-math>. But if a change would increase the energy <d-math>\Delta E \leq 0</d-math> we still have the probability <d-math>p(\sigma_i) \propto \exp(-\beta \Delta E) </d-math> that we change the spin.</p>

<!-- Second Section  4  -->
  <a class="marker" href="#section-4" id="section-4"><span>Training</span></a>
  <h2 id="training">Training</h2>

  <p>Picture an experimenter standing in front of a physical implementation of a energy function. The question now arises: what do we need to train such a system on a given data set? As we discussed before, the only thing we can do is sampling from this machine. Therefore training a Boltzmann machine means that we have to adjust the couplings and local fields of a randomly initialized spin model until its configurations show the same distribution as a our training data. For this we have to come up with an update rule for the model parameters simply by comparing the samples with the training data. We will show how the contrastive divergence algorithm <d-cite key="carreira-perpinan_contrastive_nodate"></d-cite> naturally follows from Hopfield's ideas of learning and unlearning. We will put this in contrast to the minimization of the Kullback-Leibler (KL) distance that is commonly used in the machine learning literature and finally we offer an alternative physics interpretation of learning via an equilibration approach.</p>

  <div class="row">
  <div class="column">
  <p class="slider-label-text">Training progress</p>
  <p id="temperature_slider" class="slider-label-number"></p>
    <input id="temp_slider_id" type="range" oninput="slider_fct_image_energies(this.value)" min="0" max="100" step="1.0">
  </div>
    <div class="doublecolumn">
    <p class="figure-text">add some text here</p>
    <figure style = "width:700px; height:500px; display:block; margin-left:auto; margin-right:auto; position:relative" id = "image_energies">
  <div id = "image_energies_id" style="position:absolute; left:0px; top:0px"></div>
  </figure>
  </div>
  </div>
  <script type = "text/javascript" src = "image_energies_script_new.js" ></script>
  <div class="triplecolumn"><p class="figure-text"><b>The purpose of training </b>is to find the model parameters that make the wanted configurations low energy. The model parameters are initiallized randomly and therefore the configuration's energies are also random. During the training we want to minimize the energies of the images we want to learn where at the same time we maximize the energies of configurations we don't want. This figure illustrates the evolution of energies over the training progress.</p></div>

<!-- Second Section  4.1  -->
  <a class="marker" href="#section-4.1" id="section-4.1"><span>Hopfield networks: training at zero temperature</span></a>
  <h3 id="hopfield-networks-training">Hopfield networks: training at zero temperature</h3>

  <p>The training procedure is a search for the parameters of the system's energy function which maximize the entropy and fulfil the constraints: in energy-based models, the procedure is nothing else than minimizing the energies of wanted configurations and avoiding to have energy minima for unwanted configurations. If we consider a Hopfield model the constraints are given by the expectation values 
<d-math>\langle \sigma_i \sigma_j \rangle </d-math>, <d-math>\langle \sigma_i \rangle</d-math> and we want to find the coupling parameters <d-math>w_{i,j}</d-math> and the local fields <d-math>h_i</d-math> of the energy function. To learn these system parameters we slowly change the parameters of the system until the expectation values of the model get closer of the expectation values of the data, leading to the memorization of the observed patterns.</p>

  <p>The training of a Hopfield network is deterministic and we update the weight matrix according to the Hebbian learning rule <d-cite> </d-cite> which is simply the outer product of the <d-math>n</d-math> input vectors <d-math>\{ \vec{\sigma}^{\alpha}\}_{\alpha}^n</d-math> that have to be memorised. Therefore the weights <d-math>W = \sum_{\alpha}^n( (\vec{\sigma}^{\alpha})^T \vec{\sigma}^{\alpha} - \mathbb{1}) </d-math>, which can be written as an update rule <d-math>w_{i,j} \leftarrow \sum_{\alpha}^n \sigma_i^{\alpha} \sigma_j^{\alpha}, \forall~i \neq j</d-math> , the subtraction of the identity matrix takes care that the nodes are not connected with themselves. The average over all the data instances <d-math>\alpha</d-math> is also often written as <d-math>\langle \sigma_i \sigma_j \rangle_{\text{Data}}</d-math>. This weight matrix leads to a energy landscape where each training vector is exactly a local minimum. And if we feed a slight variation of one of the input vectors into the network, the update rule will make them converge to the configuration that is associated with the closest energy minimum. The memory capacity of Hopfield networks is very limited and the more data we want to memorize, the higher is the chance to get so called spurious minima<d-footnote> Hebbian learning from page 354, <a href="http://page.mi.fu-berlin.de/rojas/neural/chapter/K13.pdf">http://page.mi.fu-berlin.de/rojas/neural/chapter/K13.pdf</a></d-footnote>. These are local energy minima which minimize the energy for configurations that are not part of the training and therefore will lead to wrong memories</p>

  <p>In <d-cite key="hopfield1983unlearning"></d-cite> Hopfield studied the effect of “unlearning” on the performance of Hopfield networks. They found that "unlearning" can help to get rid of supurous minima and therefore has a stabilizing effect on the memory of such a network. For unlearning, we expand the update rule <d-math>w_{i,j} \leftarrow \langle \sigma_i \sigma_j \rangle_{\text{Data}}</d-math> to <d-math>w_{i,j} \leftarrow \langle \sigma_i \sigma_j \rangle_{\text{Data}} - \epsilon \langle \sigma_i' \sigma_j' \rangle</d-math>. To obtain <d-math>\vec{\sigma}'</d-math>, the network is initialized in a random configuration <d-math>\vec{\sigma}</d-math> and the nodes are updated according to the update rule Eq. <d-footnote>Hopfield update rule <d-math> \sigma_{i}\leftarrow \left\{{\begin{array}{ll}+1~{\text{if }}\sum _{{j}}{w_{{ij}}\sigma_{j}}\geq h _{i},\\-1~{\text{otherwise,}}\end{array}}\right.</d-math></d-footnote> until the network equilibrates to <d-math>\vec{\sigma}'</d-math>. Therefore the configuration <d-math>\vec{\sigma}'</d-math> is a local minimum of the energy landscape and the term <d-math>- \epsilon \langle \sigma_i' \sigma_j' \rangle</d-math> increases the energy of this minimum by a small factor <d-math>\epsilon<1</d-math>. This plays against the first term of the update rule <d-math>\langle \sigma_i \sigma_j \rangle_{\text{Data}}</d-math> which minimizes the energies of the data inputs. The interplay of these two terms decreases the occurence of spurous minima. In the training of Boltzmann machines, similar terms appear, but they are often referred to as the positive and the negative phase.</p>

  <div class="row">
  <div class="column">
  <p class="slider-label-text">Learning and unlearning</p>
  <p class="figure-text">A learning step decreases the energy of the configurations, which we want to learn.</p>
    <input id="learn_button_id" type="button" value="Learning step" onclick="learn_phase()">
  <p class="figure-text">A unlearning step increases the energy of all configurations that are in a local energy minima. </p>
    <input id="learn_button_id" type="button" value="Unlearning step" onclick="unlearn_phase()">
  <p class="figure-text">Reinitialize the weights randomly.</p>
    <input id="learn_button_id" type="button" value="Reinitialize" onclick="reinitialize_phase()">
    <p class="figure-text">This figure shows how learning and unlearning changes the energy landscape.</p>
  </div>
  <div class="doublecolumn">
    <figure style = "width:100%; height:300px; display:block; margin-left:auto; margin-right:auto; position:relative" id = "energy_landscape">
  <div id = "energy_landscape_figure_id" style="width:100%, height:100%, position:absolute; left:0px; top:0px"></div>
  </figure>
  <script type = "text/javascript" src = "energy_landscape.js" ></script>
  </div>
  </div>

<!-- Second Section  4.2  -->
  <a class="marker" href="#section-4.2" id="section-4.2"><span>Boltzmann machines: training at finite temperatures</span></a>
  <h3 id="the-ising-model-in-finite-temperature">Boltzmann machines: training at finite temperatures</h3>

  <p> If we set a finite temperature in an energy-based model, say <d-math>T=1</d-math><d-footnote>The actual value does not matter so much, since it can be absorbed in the weights of the model.</d-footnote>, it will no longer be deterministic and all the configurations can occur with a certain probability.
  We will show that as long as hidden units are not available, it is hard or even impossible to learn more complex configurations. There are several simple examples of datasets that are not learnable by a finite temperature Ising model without hidden units. One of them is the logical XOR gate that has the configurations (-1-1-1, -111, 1-11, 11-1). (ADD REF <d-footnote> Hebbian learning from page 354, <a href="http://page.mi.fu-berlin.de/rojas/neural/chapter/K13.pdf">http://page.mi.fu-berlin.de/rojas/neural/chapter/K13.pdf</a></d-footnote>
  It is not possible to make these four configurations low energy, while all other configurations are at high energy. To avoid this problem one can add a "dummy" spin that can be in an arbitrary state, which we simply do not consider as a result. The states (-1-1-11, -1111, 1-111, 111-1) are learnable and if we consider the first 3 spins our "data" we learned an XOR gate.
  </p>

  <p> In the figure below is a fully functional Ising model with <d-math>T=1 </d-math>, where we can add hidden nodes and also make it restricted. Try to make the "Bars and Stripes" images maximally likely by adjusting the weights and biases. You will see that this task is impossible if you don't have hidden units.</p>

  <div class="row">
  <div class="column">
  <p id="weight_slider_text" class="slider-label-text">Weight</p>
  <p id="weight_slider_value" class="slider-label-number"></p>
    <input id="weight_slider_id" value=0 type="range" onchange="slider_fct_RBM(this.value,1)" min="-2" max="2" step="0.01">
  <p id="bias_slider_text" class="slider-label-text">Bias</p>
  <p id="bias_slider_value" class="slider-label-number" width="50%"></p>
    <input id="bias_slider_id" value=0 type="range" oninput="slider_bias_just_text(this.value)" onchange="slider_bias_fct_RBM(this.value,1)" min="-2" max="2" step="0.01">
  <div>
  <input type="checkbox" onclick="change_layout_hidden()" id="hidden_check" name="hidden_check"
         checked>
  <label for="hidden_check">Allow hidden units</label>
  </div>
  <div>
  <input type="checkbox" onclick="change_layout_restricted()" id="restricted_check" name="restricted_check">
  <label for="restricted_check">Make it restricted</label>
  </div>
  </div>
  <div class="doublecolumn">
    <p class="slider-label-text">Unnormalized Probability </p>
    <figure style = "width:100%; height:320px; display:block; margin-left:auto; margin-right:auto; position:relative" id = "RBM_complete">
  <div id = "RBM_complete_id" style="position:absolute; left:0px; top:0px"></div>
  </figure>
  <script type = "text/javascript" src = "RBM_complete_new.js" ></script>
  </div>
  </div>
  <div class="caption-triplecolumn"><p class="figure-text"> Try to make the "Bars and Stripes" configurations maximally likely.
  For this you have to adjust the weights and biases by clicking on the conections and the biases and adjust them with the slider.
  The color of the nodes indicates in which direction the spins are. This can help you to find the weights for a certain configurations and make its energy high or low. Remember that the wanted configurations should be low energy. And all the others should be higher energy. A way to find the solution for this task is to set the spins of the model to a B&S configuration and make its energy as small as possible. Then change to another B&S configuration and repeat. You will figure out eventually how you "learn" the weights. If you want to have a working solution, click the solution button.</p></div>

  <p>More complex target distribution cannot be approximated without hidden nodes. To only use a Ising system to model data, where every spin represents a data point, will not be sufficient. A much more expressive model is the Boltzmann machine, where we start to distinguish between visible and hidden spin variables. On first glance there is no difference between the two models except the name of the nodes. But the crucial point is that only the visible units are used to represent data. The hidden units are only there to increase the space of possible configurations and their state will be ignored in the end. This way we can increase the expressivity of the model.</p>

  <p>Learning certain configurations means that the model parameters have to be adjusted in a way that the model distribution fits the target distribution. This task can be very demanding because all the parameters influence each other and a small change in the wrong direction can influence the probability distribution strongly. In real-world applications, each training step or parameter update only makes small adjustments.</p>

  <a class="marker" href="#section-4.3" id="section-4.3"><span>Contrastive divergence</span></a>
  <h3 id="r-bm-and-sampling">Contrastive divergence</h3>
  <p>As already discussed before, in physics equilibration occurs naturally and if we could implement a Boltzmann machine as a real system we could use the learning-unlearning approach to train the model, because it is actually possible to sample from it. A numerical implementation of a Boltzmann machine, on the other hand, would not allow us to sample from it. The problem is relatively simple: If a random initial configuration <d-math> \vec{\sigma} </d-math>is given, we have to update the spins to get to minimum energy. But if we update a single spin the probabilities for all the other spins to be in a certain direction might change drastically. To equilibrate such a system one would have to update the spins many times one after another and even then there is no gurantee to equilibrate.
  Therefore it is almost impossible to equilibrate to minimum energy if we numerically update spin after spin.</p>

  <p>To overcome this problem the restricted Boltzmann machine has been introduced. The idea here was, if we only allow couplings between the layers and not within the same layer, the probabilities of the single nodes of one layer become independent e.g. for the visible nodes <d-math>p(\vec{v}| \vec{h}) = \prod_i p(v_i | \vec{h}) </d-math>. This allows us to update a whole layer <d-math> \vec{v}</d-math> at a time only dependent on the other layer <d-math> \vec{h}</d-math> and vice versa. Furthermore, so far we assumed that we have access to the probability distribution of the energy-based model <d-math>p(x, \theta)</d-math> or for Boltzmann machines, <d-math>p(v,h, \theta)</d-math> and the data <d-math>p(v)</d-math>. In general, this is not true because the partition function <d-math>Z(\theta)</d-math> is not tractable for systems of the size <d-math>N>20</d-math>. Therefore to compare the statistics of the data with the statistics of the model we need to be able to approximate these distributions. For the data, this is relatively simple, since we can average over some data instances, for example over batches. On the other hand, to approximate the model distribution, we need configurations that come from the model itself. For a real physical system we therefore would set the parameters of the model, initialize some spin configuration and wait until it equilibrates. We would repeat this step and take many configurations and compare them to the data. Unfortunately we cannot simulate these equilibration dynamics on a computer because it is computationally intractable. What we can do is a Monte Carlo method called Gibbs sampling. To avoid this problem the graph of the Boltzmann machine can be made bipartite, which means that we separate the nodes in a visible and a hidden layer and don’t allow inter-layer connections. This architecture is called restricted Boltzmann machine. With this simple trick the conditional probabilities <d-math>p(\vec{v}|\vec{h})</d-math> and <d-math>p(\vec{h}|\vec{v})</d-math> marginalize and therefore we can sample each node of a layer independent of the other nodes of the same layer.</p>

  <p>Contrastive divergence (Cite Hinton) makes it possible to train RBMs efficiently. We would like to model the probability distribution of our data <d-math>p(x) </d-math> with a RBM which is nothing else than a parameterized probability function <d-math> p(x, \theta) </d-math>. Therefore during the training we want to make these two probability distributions as similar as possible. This similarity can be measured by the Kullback-Leibder divergence <d-math> KL(p(x)|p(x, \theta)) = \log(p(x)) \frac{p(x)}{p(x,\theta)} </d-math>. So in the end what we do is stochastic gradient descent with respect to the parameter <d-math> \theta </d-math>. If we calculate the derivatives, we find the update rule of the contrastive divergence algorithm algorithm:
  <d-math block> \Delta W_{i,j} = \langle v_i h_j\rangle_{\text{Data}} - \langle v_i h_j\rangle_{\text{Model}}</d-math>
  This is exactly the same update rule as already introduced by Hofield with the learning and the unlearning term. The only difference is that there are visible and  hidden units involved and that the same kind of units are not connected. Therefore terms like <d-math>\langle v_i v_j \rangle = 0</d-math>, but the intuition behind contrastive divergence is exactly the same. The learning term, <d-math> \langle v_i h_j\rangle_{\text{Data}}</d-math>, which for Boltzmann machines is mostly referred to as the positive phase decreases the energy of the configurations of the training data. The unlearning term <d-math> \langle v_i h_j\rangle_{\text{Model}}</d-math>, which is often referred to as the negative phase, increases the energy of all the configurations that are at equilibrium and therefore at low energy.
  </p>

<!-- Second Section  4.4  -->
  <a class="marker" href="#section-4.4" id="section-4.4"><span>Training and equilibrium</span></a>
  <h3 id="training-and-equilibrium">Training and equilibrium</h3>
  <p>To give some physical intuition about contrastive divergence training, in particular how it relates to equilibrium, it is instructive to picture both our model and the training data as physical systems. The identification of binary variables with physical spins, as was done above, is a common connection between energy-based models and physical systems. However, for illustrative purposes, we will consider physical systems which may be more familiar and intuitive to many: objects moving in Earth's gravitational field. Now, energy-based systems, be they physical systems or statistical models, can take many possible configurations. Each configuration <d-math>\vec{x}</d-math> has an associated energy 
<d-math>E(\vec{x})</d-math>. The probability of observing a particular configuration of a system is proportional to the energy of that configuration (with the functional form of the energy specified by the physics of the situation or by the designer of the statistical model). 
  </p>

  <p>In elementary physics, energy is the product of <i>force</i> and <i>position</i>: <d-math>E = F\times x</d-math>. For example, the gravitational force felt on Earth by an object of mass <d-math>m</d-math> is equal to <d-math>F_g=mg</d-math> (where <d-math>g=9.8m/s^2</d-math> is a constant called <i>standard gravity</i>), and position is measured by the height <d-math>h</d-math> from the surface. The energy associated to gravity is thus given by the product <d-math>E = mgh</d-math>. The only way to change the position of an object is to apply an upwards force which counteracts the force of gravity. In other words, <i>forces generate changes in position</i>. Conveniently, in many scenarios, we can often break energy down into a product of so-called <i>conjugate variables</i>, analogous to a force and a position, even if these quantities are physically nothing like forces or positions. These quantities have the official-sounding names of <i>generalized forces</i> and <i>generalized coordinates</i> (or generalized displacements). The main intuition we need is that -- like real forces -- generalized forces drive changes in the values of the cooresponding generalized coordinates. One example of a conjugate variable pair is the pressure and volume of an enclosed gas. Changes in pressure <d-math>p</d-math> drive changes in volume <d-math>V</d-math> (like blowing up a balloon or expanding a piston). In this example, pressure has the role of a generalized force, and volume that of a generalized coordinate, with the product <d-math>E=pV</d-math>. More generally, an energy function can be built up from a number of contributing generalized force/coordinate pairs <d-math>E = \sum_i F_i q_i</d-math>.
  </p>

  <p>Objects on Earth are always under the pull of the Earth's gravity. If the force provided by a gravity well were the only force, objects would constantly be in motion, changing position from moment to moment. However, many objects are able to maintain a state of equilibrium with gravity, remaining at the same position for long periods of time. This is because there are many other forces which compete against the force of gravity, e.g., the upwards force imparted by the Earth's surface onto our bodies. An object is in equilibrium (no changes in position) when all these forces are balanced. In the case of two forces -- say, gravity <d-math>F_g</d-math> and the restoring force provided by the Earth's surface <d-math>F_\mathrm{surface}</d-math>) -- equilibrium occurs when <d-math>F_g=F_\mathrm{surface}</d-math>. When forces are out of balance -- like a rocket or plane wing producing an upwards thrusting force <d-math>f_\mathrm{up}</d-math> --- then changes in an object's position <d-math>h</d-math> are generated. To first order, these changes are given by 
	<d-math block> 
		h \rightarrow h + \eta(F_\mathrm{up} - F_\mathrm{g}).
	</d-math>
To emphasize: objects are in equilibrium (no changes in coordinates from moment to moment) when the forces acting on them are balanced. When the forces are unbalanced, this generates changes in coordinates proportional to the net difference of forces.
  </p>

  <p>Now we connect back to energy-based models. We can generically write the energy functions of these models as <d-math>E(x) = \sum_i \theta_i x_i</d-math>, where the parameters <d-math>\theta_i</d-math> are the weights and biases of the model and <d-math>x_i</d-math> contain the random variables (the visible units, the hidden units, and their products). This energy function has the same form as the physical force-based approach discussed above. Specifically, we can identify the model parameters (the <d-math>\theta_i</d-math>) as the coordinates, and the random variables (the <d-math>x_i</d-math>) with the forces (for compactness, we drop the word 'generalized').<b>PW: notation to be harmonized</b>
  </p>

  <p>With a contrastive-divergence-type update rule, we are effectively mimicking the process of a physical system equilibrating against some forces, using successive small time steps. We first evaluate the forces at the current coordinates. These correspond to
<d-math>F_\mathrm{data} = \langle x_i \rangle_{\mathrm{data}}</d-math> and 
<d-math>F_\mathrm{model} = \langle x_i \rangle_{\mathrm{model}}</d-math>. The first fictitious force, <d-math>F_\mathrm{data}</d-math>, can be thought of as an external force provided by an outside system, like the Earth's gravitational field. In this case, the external system is actually a set of training data. These data provide a constant downward "pull" towards preferred configurations which are exemplified in the dataset. 
The second fictitious force, F_\mathrm{model}, represents the system's natural preference for certain configurations. This provides a certain kind of internal "lift", working against the downward pull of the training data. 
  </p>

  <p>When one of the forces dominates the other (e.g., the expectatation value <d-math>\langle x_k \rangle</d-math> is much higher for the training data than for samples generated by the model), the above update rule will force large changes in the corresponding coordinate <d-math>\theta_k</d-math>. This coordinate will keep changing strongly over successive updates until <d-math>\langle x_k \rangle_\mathrm{model}</d-math> more closely resembles <d-math>\langle x_k \rangle_\mathrm{data}</d-math>.
If a particular expectation value (or coordinate) <d-math>\langle x_k\rangle</d-math> is preferred in equal proportions by both the data and the model, then the corresponding forces will balance (<d-math>\langle x_k \rangle_{\mathrm{data}} = \langle x_k \rangle_{\mathrm{model}}</d-math>), and the coordinate <d-math>\theta_k</d-math> will remain constant. If this holds true for all coordinates <d-math>\langle x_i\rangle</d-math>, then all forces are counterbalanced and progressive updates will not change the model further, i.e., we are finished training. This also means that the sufficient statistics of our model (the expectation values) must match the corresponding values from the external dataset; this is the best outcome one can hope for a fixed choice of energy function. 
  </p>

<!-- Second Section  4  -->
  <a class="marker" href="#section-5" id="section-5"><span>Conclusion</span></a>
  <h2 id="conclusion">Conclusion</h2>

  <p><b>PW: we should finish the conclusions with a paragraph on how these insights will help develop new energy-based models, e.g., new QBMs, continuous-valued stuff, what-not.</b></p>

  <script>
    const figure = document.querySelector("d-figure#last-figure");
    const initTag = document.createElement("span");
    initTag.textContent = "initialized!"
    figure.appendChild(initTag);
    figure.addEventListener("ready", function() {
      const initTag = figure.querySelector("span");
      initTag.textContent = "ready"
      console.log('ready')
    });
    figure.addEventListener("onscreen", function() {
      const initTag = figure.querySelector("span");
      initTag.textContent = "onscreen"
      console.log('onscreen')
    });
    figure.addEventListener("offscreen", function() {
      const initTag = figure.querySelector("span");
      initTag.textContent = "offscreen!"
      console.log('offscreen')
    });
  </script>


</d-article>

<d-appendix>

  <h3>Contributions</h3>
  <p>Some text describing who did what.</p>
  <h3>Reviewers</h3>
  <p>Some text with links describing who reviewed the article.</p>
<d-footnote-list></d-footnote-list>
  <d-citation-list></d-citation-list>
  <!--  <d-bibliography src="bibliography.bib"></d-bibliography> -->
<d-bibliography>
    <script type="text/bibtex">
      @article{gregor2015draw,
        title={DRAW: A recurrent neural network for image generation},
        author={Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
        journal={arXiv preprint arXiv:1502.04623},
        year={2015},
        url ={https://arxiv.org/pdf/1502.04623.pdf}
      }
      @article{mercier2011humans,
        title={Why do humans reason? Arguments for an argumentative theory},
        author={Mercier, Hugo and Sperber, Dan},
        journal={Behavioral and brain sciences},
        volume={34},
        number={02},
        pages={57--74},
        year={2011},
        publisher={Cambridge Univ Press},
        doi={10.1017/S0140525X10000968}
      }
    </script>
  </d-bibliography>

  <distill-appendix> </distill-appendix>

</d-appendix>

<distill-footer></distill-footer>

</body>
