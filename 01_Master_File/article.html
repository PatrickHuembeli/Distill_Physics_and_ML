<!--
  Copyright 2018 The Distill Template Authors

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. –
-->
<!doctype html>

<head>
  <script src="https://distill.pub/template.v2.js"></script>
  <script src='https://d3js.org/d3.v4.min.js' charset="utf-8"></script>
<!--   <script src="https://d3js.org/d3-selection-multi.v0.4.min.js"></script> -->

<script>
  function MathCache(id) {
    return document.querySelector("#math-cache ." + id).innerHTML;
  }
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1" >
  <meta charset="utf8">
  <link href="style.css" rel="stylesheet" type="text/css">
</head>
<body>
  <distill-header></distill-header>
<d-front-matter>
  <script id='distill-front-matter' type="text/json">{
    "title": "The Physics of Energy-Based Models",
    "description": "We need to understand the simple models",
    "published": "XXX xx, 2019",
    "authors": [
      {
        "author":"Patrick Huembeli",
        "authorURL":"http://patrickhuembeli.github.io/",
        "affiliations": [{"name": "ICFO-The Institute for Photonics", "url": "https://icfo.eu/"}]
      },
      {
        "author":"Juan-Miguel Arrazola",
        "affiliations": [{"name": "Xanadu", "url": "https://www.xanadu.ai/"}]
      },
      {
        "author":"Nathan Killoran",
        "authorURL":"https://github.com/co9olguy",
        "affiliations": [{"name": "Xanadu", "url": "https://www.xanadu.ai/"}]
      },
      {
        "author":"Peter Wittek",
        "authorURL":"https://peterwittek.com/",
        "affiliations": [
          {"name": "University of Toronto", "url": "https://www.rotman.utoronto.ca/"},
          {"name": "Creative Destruction Lab", "url": "https://www.creativedestructionlab.com/"},
          {"name": "Vector Institute for Artificial Intelligence", "url": "https://vectorinstitute.ai/"},
          {"name": "Perimeter Institute for Theoretical Physics", "url": "https://perimeterinstitute.ca/"}
        ]
      }
    ],
    "katex": {
      "delimiters": [
        {"left": "$$", "right": "$$", "display": false}
      ]
    }
  }</script>
</d-front-matter>
<!-- Put Title, short abstract and image -->
<d-title>
<!--   <figure style="grid-column: page; margin: 1rem 0;"><img src="momentum.png" style="width:100%; border: 1px solid rgba(0, 0, 0, 0.2);"/></figure> -->

    <figure style = "grid-column: page; margin: 1rem 0;" id = "RBM_Graph">
  <div id = "RBM_graph_id" style="left:0px; top:0px"></div>
  </figure>

  <script type = "text/javascript" src = "figures/RBM2_script.js" ></script>
  <p>Taking a closer look at the physics of energy-based models sparks new insights on the future of these architectures</p>
</d-title>
<d-byline></d-byline>
<!-- Actual Article starts here -->
<d-article>
<!--  INTRODUCTION -->
  <a class="marker" href="#section-1" id="section-1"><span>Introduction</span></a>

  <p> Inspiration takes many forms. A painter beholds a sunrise and translates its colours onto a canvas. A writer embarks on an adventure, transforming life experiences into compelling stories. A scientist attempting to design artificial intelligence systems, where do they look for inspiration? A possible starting point is to contemplate intelligence as it manifests itself in nature: living organisms that are capable of creativity and learning. But intelligent beings are extraordinarily complex. Can we instead draw inspiration from simpler, more fundamental systems? </p>

  <p> In this article, we take a journey to understand how simple forms of artificial intelligence can originate from the collective behaviour of interacting particles. In the process, we uncover fundamental physical concepts underlying the theory and practice of energy-based models, including the design, implementation, and training of Hopfield networks and Boltzmann machines. Along the way, we highlight the connection between methods in machine learning and physics, offering a new perspective on these concepts. </p>


<!-- Second Section  2  -->
  <a class="marker" href="#section-2" id="section-2"><span>Energy-based models</span></a>
  <h2 id="testing-the-bm-as-a-trained-model">Energy-based models</h2>

  <p>
  Energy-based models emerged in the machine learning literature in the 1980s [].
  They were further developed, extended, and improved, over several decades. Some energy-based models, Boltzmann machines especially, have recently been “back-ported” to physics, where they have successfully been used to model the wavefunctions of quantum systems <d-cite key="carleo2017solving"></d-cite>. They also seem to get back into the focus of fundamental research in machine learning. <d-footnote>According to this <a href="https://twitter.com/datasciencenig/status/1020355546581553152" target="_blank">tweet</a>, Yoshua Bengio as an example wants to return to studying Boltzmann machines for a better understanding of generative models.</d-footnote> Furthermore Boltzmann machines are still being employed in other areas, such as recommendation systems <d-cite key='salakhutdinov_restricted_2007'></d-cite><b>PW: We could also cite https://openai.com/blog/energy-based-models/</b> The rekindled interest is understandable: many types of energy-based models are generative, guarantee to sample a valid probability distribution, and they can often be stacked to create deep, hierarchical representations <b>PW: Cite the deep belief network paper</b>.</p>

  <p>
  To understand the origin of energy-based models, imagine being an ambitious experimental scientist attempting to build a physical system that is capable of intelligent behavior. This is indeed an ambitious goal. For instance, being able to fully control a large collection of particles is challenging; typically they move randomly as they interact with the environment. Therefore, as an initial strategic choice, let's aim to use these random fluctuations to our advantage and design <em>probabilistic systems</em>. Mathematically, these are characterized by a probability distribution that determines the likely configurations of the system at different times. The challenge is to design systems that are sufficiently complex to give rise to rich behaviour, but also simple enough that they can be efficiently trained and characterized. </p>

<p>
For large systems, it is intractable to keep track of all its rapidly-fluctuating internal degrees of freedom; we typically can only expect to have access to coarse-grained information like the total energy of the system. For a given system, the laws of physics allow us to determine the system's energy for any given configuration. This is encapsulated in terms of an <em> energy function </em> <d-math> E(x) </d-math> that assigns energy values to the possible states 
<d-math> x=(x_1, x_2, \ldots, x_n) </d-math> of an <d-math>n</d-math>-particle system. Now a question arises: given the constraint that the average energy <d-math> \langle E(x) \rangle </d-math> of the system is fixed, what probability distribution should we assign to its specific configurations? Intuitively, it makes sense to choose the distribution with maximum entropy: if we do not have any information – and therefore no constraint – about a particular degree of freedom of a system, we should remain maximally flexible in our choice of model while remaining consistent with the quantitites that are constrained. Choosing the maximum entropy model thus reduces the amount of potentially biased or unsubstantiated prior information built into a model. This strategy is known as <em> Jaynes' maximum entropy principle </em>, which states that in assigning a model on the basis of partial available information, we should assign the distribution with the largest possible entropy. The resulting distribution <d-math> P(x) </d-math> is the solution to the optimization problem

 <d-math block>
  \begin{aligned}
  &\max_{P(x)}\,\,  \sum_x -P(x)\log P(x) \\[0.4em]
   \text{s.t. }& \sum_x P(x) E(x) = \langle E \rangle,
  \end{aligned}
  </d-math>

whose solution is []
 <d-math block>
  P(x) = \frac{1}{Z} \exp\left[ - E(x)/T \right],
 </d-math>
where  <d-math>T </d-math> is a free parameter and <d-math> Z=\sum_x \exp[- E(x)/T] </d-math> is a normalization constant known as the <em>partition function</em>. This probability distribution is a familiar one in statistical physics: it is the <em> Boltzmann distribution </em>, which describes the probability of finding the system in a state <d-math>x</d-math> when it is in thermal equilibrium with a bath at temperature <d-math> T </d-math>. The Boltzmann distribution establishes a concrete relationship between energy and probability: low-energy configurations are the most likely to be observed. In the context of machine learning, probabilistic models governed by the Boltzmann distribution are known as <em>energy-based models</em>. </p>

<p>
Typically, the energy function of a physical system can be expressed as a sum over several contributions arising both from the internal energy of each particle and the interactions between them. In such cases, the energy function can be written as <d-math> E(x) = \sum_i \theta_i f_i(x) </d-math> for appropriate parameters <d-math>\theta_i </d-math> and functions <d-math>f_i(x)</d-math>. The resulting Boltzmann distribution for a given temperature <d-math> T </d-math> is then uniquely determined by the parameters <d-math>\theta_i </d-math> or, equivalently, by the expectation values <d-math>\langle f_i(x)\rangle </d-math>, which are the <em> sufficient statistics </em> of the distribution<d-footnote> Insert footnote explaining sufficient statistics for the exponential family </d-footnote>. Knowledge of the expectation values <d-math>\langle f_i(x)\rangle </d-math> fixes the parameters <d-math>\theta_i </d-math> of the energy function and therefore the resulting properties of the Boltzmann distribution.
</p> 

<p>
We are now in good shape: collections of interacting particles at thermal equilibrium lead to probabilistic models that can be characterized by a relatively small number of parameters. This paves a path to designing energy functions and training their parameters to build systems that perform interesting tasks. Before proceeding, it is important to recognize the unique role of the temperature parameter: it determines the relative probability of observing higher-energy configurations, not just the lowest energy ones. In particular, in the limit of zero temperature, only those configurations corresponding to global minima of the energy function can be observed, while in the limit of infinite temperature, all configurations are equally likely. The role of temperature in the Boltzmann distribution is illustrated in Fig. 1. Physically, temperature quantifies the average energy of the interactions between the system and environment, which in turn lead to sporadic "jumps" towards configurations of higher energy. The higher the temperature, the more common and widespread such jumps will be.
</p>


<!-- Figure Section 2.2  -->
  <div class="row">
  <div class="column">
  <p class="slider-label-text">Temperature: </p>
  <p id="temperature_slider" class="slider-label-number"></p>
    <input id="temp_slider_id" type="range" onchange="temp_slider(this.value)" oninput="update_number_temp(this.value)" min="0.001" max="1" step="0.01">
    <p class="slider-label-text">Energy Gap: </p>
    <p id="energy_slider" class="slider-label-number" width="100%"></p>
    <input type="range" onchange="energy_slider(this.value)" oninput="update_number_e(this.value)" min="0" max="10" step="0.01">
    <p class="figure-text">2-level system with temperature. This is a simple model that shows the influence of temperature on the probability to be in a certain state. If the system is at zero temperature only the low energy state can be occupied. If the temperature is increased the higher energy level can also be occupied. If we are at very high temperature, both states get equally likely. </p>
  </div>
  <div class="doublecolumn">
    <p class="slider-label-text">Unnormalized Probability </p>
    <figure style = "width:100%; height:280px; display:block; margin-left:auto; margin-right:auto; position:relative" id = "RBM_complete">
    <figure id="temperature">
  <div id = "test_figure_id" style="position:absolute; left:0px; top:0px"></div>
  </figure>
  <script type = "text/javascript" src = "2-level-sys_new.js" ></script>
  </div>
  </div>
  <div class="triplecolumn"> <p class="figure-text">This figure shows the effect of temperature on the occupation probability of a higher energy state. If the energy difference between the sates is big and the temperature is low, the probability of the system to be in the higher energy state goes to zero. On the other side if the temperature increases or the energy gap closes the system gets more likely to be in the higher energy state.<p></div>



<!-- Second Section  2  -->
  <a class="marker" href="#section-2.4" id="section-2.4"><span>Architectures</span></a>
  <h3 id="architecture">Architectures</h3>
<p>
The decision remains of what physical systems and energy functions we should select. A reasonable choice is to start with arguably the simplest interesting model: a collection of particles with only two degrees of freedom whose energy function depends on both the particle's individual state as well as the interactions between pairs of particles. Note that to build interesting models, we can anticipate the need for interactions, since otherwise each particle behaves independently. Given this choice of systema nd energy funciton, we describe the configurations of <d-math>n</d-math> particles in terms of the vector <d-math> \sigma=(\sigma_1, \sigma_2, \ldots, \sigma_n) </d-math>, where <d-math>\sigma_i\in\{-1, 1\}</d-math> is the state of the <d-math>i</d-math>-th particle. The resulting energy function is given by
<d-math block>
E(\sigma) = \sum_i b_i \sigma_i + \sum_{ij} w_{ij} \sigma_i\sigma_j,
</d-math> 
which is known as the <em> Ising model </em>, first introduced as a mathematical description of interacting spins in the presence of a magnetic field []. <b>JM: Other conventions for the Ising Hamiltonian are an option. </b> The parameters <d-math> b_i </d-math> determine the individual energies of the spins, while the parameters <d-math> w_{ij} </d-math> introduce energy contributions due pairwise interactions: for <d-math> w_{ij}>0 </d-math>, equal configurations <d-math>(\sigma_i=\sigma_j)</d-math> have higher energy, while for <d-math> w_{ij}<0 </d-math>, opposite configurations <d-math>(\sigma_i\neq\sigma_j)</d-math> lead to higher energies. At this stage, we make another strategic choice: experimentally, it is extremely challenging to engineer physical systems that represent Ising models with arbitrary parameters. Therefore, despite our imagined role as ambitious experimental physicists, instead of building these systems in a laboratory, we aim simulate them using computer models. In particular, this gives freedom to explore a wide variety of systems without worrying about experimental constraints. </p>

<p>
What tasks can we perform with such models? Consider the zero temperature case. At equilibrium, only the lowest-energy configurations can be observed; if the system is set to a configuration with higher energy and then allowed to equilibrate back to zero temperature, it will revert to one of the "ground states" with lowest energy. If we encode data into the ground states of the system, the model will have the ability -- through equilibration -- to retrieve data instances from incomplete or corrupted inputs, which are non-equilibrium configurations. In other words, the model can serve as an <em>auto-associative memory</em>, capable of "remembering" patterns when similar ones are given as input. Such models are known as <em>Hopfield networks</em>. The parameters <d-math> w_{ij} </d-math> in the energy function can be viewed as weighted edges in a graph and therefore the model can be represented by a network -- a neural network when particles themselves are viewed as neurons.    
</p>

<p>
Hopfield networks are not entirely general. For example, their corresponding energy function considers only pairwise interactions between spins. Nevertheless, extending the scope to more complicated models comes at a significant price as they will typically be more difficult to train, analyze, and simulate. Instead, we can use a trick: new spins can be added to the network which are not used to represent data, but whose role is to increase the overall complexity of the model. They are referred to as <em>hidden</em> nodes (as in nodes in a graph) and they act as intermediaries between the remaining <em>visible</em> nodes of the network. Each collection of hidden or visible nodes is known as a <em>layer</em>. Physically, the hidden nodes enable effective higher-order interactions between visible nodes, leading to a new effective energy function for the visible nodes. <b>JM: A reference here would be great PH: https://www.iro.umontreal.ca/~lisa/pointeurs/TR1312.pdf here they show that RBM are universal. Here they give examples what hidden units are useful for http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf</b>. The resulting networks are called <em>Boltzmann machines</em>, in allusion to the Boltzmann distribution governing their behaviour. They are generalizations of Hopfield networks in the sense that they are contained as a special case: a Boltzman machine is equivalent to a Hopfield network when the interactions <d-math>w_{ij}</d-math> between hidden and visible nodes are set to zero. Importantly, Boltzmann machines are not only more powerful than Hopfield networks, but in a sense as powerful as they can be: they are universal approximators, in principle able to replicate any discrete probability distribution with arbitrary precision [].
</p>

<p>
Finally, as we'll discuss in upcoming sections, simulating and training Boltzmann machines can be challenging. To make things easier, we study models where some connections are set to zero. In the most extreme case, all intralayer connections are removed, leaving present only connections between visible and hidden nodes. The resulting models are known as <em> Restricted Boltzmann machines </em> (RBMs). Conventionally, the state of an RBM is written in terms of visible and hidden nodes, <d-math>\sigma=(v, h)</d-math> with its energy function given by <d-math>E(v, h)=\sum_i b_iv_i+\sum_j c_jh_j + \sum_{ij}w_{ij}v_ih_j</d-math>. Compared to the fully-connected Boltzmann machine, the RBM is less expressive, as there are fewer parameters. Nevertheless, the advantages gained in simulating and training these models greatly away the loss in expressivity, especially since, following the principles of statistical learning theory[], less complex models tend to generalize better if their training error is comparable to a more complex model (CITE https://arxiv.org/pdf/1706.08947.pdf). The three fundamental energy-based models we study in this article, Hopfield networks, Boltzmann machines, and RBMs, are illustrated in Fig. 2.
</p>

  <div class="row">
  <div class="column">
    <p class="figure-text">Hopfield network: The number of nodes is equal to the size of the input data. There are no hidden nodes (dashed) contributing to the energy.</p>
    <figure style = "width:100%; height:280px; display:block; margin-left:auto; margin-right:auto; position:relative" id = "architecture_Hopfield">
  <div id = "architecture_Hopfield_id" style="position:absolute; left:0px; top:0px"></div>
  </figure>
  </div>
  <div class="column">
    <p class="figure-text">Boltzmann machine: The Boltzmann machine graph is fully connected. The visible nodes (blue) are clamped to the input data. The hidden nodes (yellow) are free parameters.</p>
    <figure style = "width:100%; height:280px; display:block; margin-left:auto; margin-right:auto; position:relative" id = "architecture_BM">
  <div id = "architecture_BM_id" style="position:absolute; left:0px; top:0px"></div>
  </figure>
  </div>
  <div class="column">
    <p class="figure-text">Restricted Boltzmann machine: Also with hidden and visible nodes, but we don't allow connections within the same layer. This will simplify the training.
    <figure style = "width:100%; height:280px; display:block; margin-left:auto; margin-right:auto; position:relative" id = "architecture_RBM">
  <div id = "architecture_RBM_id" style="position:absolute; left:0px; top:0px"></div>
  </figure>
  </div>
  </div>
  <script type = "text/javascript" src = "architecture.js" ></script>



<!-- Second Section  3.1  -->
  <a class="marker" href="#section-3.1" id="section-3.1"><span>Sampling</span></a>
  <h3 id="sampling">Sampling</h3>
<p>
From an experimental perspective, given a collection of particles governed by a specific energy function, sampling from its Boltzmann distribution at a given temperature is straightforward: we simply place the system in contact with an environment at the desired temperature and register the system's state at different times. The challenge we now face is to simulate this process with computer algorithms.  </p> 

<p>
Consider first the zero-temperature case. The key physical principle underlying the Boltzmann distribution is the connection between energy and probability: the likelihood of observing a specific configuration decreases exponentially with its energy. A strategy to simulate sampling from a Boltzmann distribution is to identify low-energy configurations and, depending on temperature, ocassionally select also states with higher energy. One simple strategy to find low-energy configurations is to locally change the state of each particle in such a way that it decreases the total energy of the system. For an Ising energy function, when keeping the state of all other particles fixed, the change in energy <d-math>\Delta E</d-math> introduced by changing the <d-math>i</d-math>-th particle's state from <d-math>\sigma_i</d-math> to <d-math>-\sigma_i</d-math> is given by <d-math>\Delta E = 2\sigma_i(b_i+\sum_j w_{ij} \sigma_j)</d-math> <b>JM: Should double-check. PH: Should be fine now.</b>. With this in mind, to search for equilibrium states of the system, we iteratively apply the update rule

<d-math block>\sigma_{i}\rightarrow \left\{{\begin{array}{ll}-\sigma_i~{\text{if }} b_i+\sum_j w_{ij} \sigma_j >0,\\\sigma_i~{\text{otherwise,}}\end{array}}\right.</d-math>

Starting from an initial random configuration, by repeatedly applying this update rule for each particle, the system's configuration will converge to a local minimum []. This method is in general not guaranteed to find the true ground states, i.e., global minima of the energy funciton, but it can nevertheless work sufficiently well in practice []. <b>This statement needs to be better supported.</b> For finite temperature, the strategy is similar, except that we allow the possibility to ocassionally jump to higher-energy configurations. In this case, the update rule is as follows: as before, if a change of state decreases the total energy, we apply that change: <d-math>\sigma_i \rightarrow -\sigma_i</d-math>. However, if a change increases the energy, i.e., if <d-math>\Delta E \geq 0</d-math>, instead of leaving the particle's state unchanged, we now flip it with probability <d-math>p = \exp(-1/T \Delta E) </d-math>. Physically, these jumps to higher-energy states mimic the random thermal fluctuations arising from exchanging energy with an environment at finite temperature.</p>

<p>
Connection to Metropolis-Hastings. Could be improved by updating more at the same time, but in general difficult. However, for RBMs we can update entire layers at a time beacuse distribution marginalizes. In fact, here we can explicitly compute marginal distributions, so we introduce update rule depending on marginal probability. This is Gibbs sampling.

</p>

    <div class="row">
    <div class="column">
    <p class="figure-text"><b>Influence of Temperature on Configurations: </b>After training local energy minima correspond to configurations of the training set. At zero temperature configurations with higher energy will equilibrate to the minimum energy configuration. For non zero temperature higher energy configurations can be occupied with a certain probability here shown as a shaded blue area around the minima.</p>
    </div>
    <div class="doublecolumn">
      <p class="slider-label-text">Energy Minima </p>
      <figure style = "width:100%; height:280px; display:block; margin-left:auto; margin-right:auto; position:relative" id = "Figure_energy_minima_and_temp">
    <div id = "energy_minima_and_temp_id" style="position:absolute; left:0px; top:0px"></div>
    </figure>
    <script type = "text/javascript" src = "energy_minima_and_temp.js" ></script>
    </div>
  </div>
  <div class="triplecolumn"><p class="figure-text"> This figure illustrates two local energy minima that contain a different MNIST number as their minimum energy. If we are at zero temperature any higher energy configuration would equilibrate to the closest local minimum and the only configurations that can be retrieved are the ones at the minimum energy. If we allow a certain temperature (blue shaded area) we can also retrieve configurations with a slightly higher energy. This eventually makes the system to generalize training data.</p></div>


<p>
Consider first the zero-temperature case. The key physical principle underlying the Boltzmann distribution is the connection between energy and probability: the likelihood of observing a specific configuration decreases exponentially with its energy. A strategy to simulate sampling from a Boltzmann distribution is to identify low-energy configurations and, depending on temperature, ocassionally select also states with higher energy. One simple strategy to find low-energy configurations is to locally change the state of each particle in such a way that it decreases the total energy of the system. For an Ising energy function, when keeping the state of all other particles fixed, the change in energy <d-math>\Delta E_i</d-math> introduced by changing the <d-math>i</d-math>-th particle's state from <d-math>\sigma_i=</d-math> to <d-math>-\sigma_i</d-math> is given by <d-math>\Delta E_i = -2\sigma_i(b_i+\sum_j w_{ij}\sigma_j)</d-math> <b>JM: Should double-check.</b>. With this in mind, to search for equilibrium states of the system, we iteratively apply the update rule 
</p>

<p>
<d-math block>\sigma_{i}\rightarrow \left\{{\begin{array}{ll}-\sigma_i~{\text{if }}-\sigma_i(b_i+\sum_j w_{ij}\sigma_j)<0,\\\sigma_i~{\text{otherwise,}}\end{array}}\right.</d-math></p>  

<p>
Starting from an initial random configuration, by repeatedly applying this update rule for each particle, the system's configuration will converge to a local minimum []. This method is in general not guaranteed to find the true ground states, i.e., global minima of the energy function, but it can nevertheless work sufficiently well in practice []. <b>This statement needs to be better supported.</b> For finite temperature, the strategy is similar, except that we allow the possibility to ocassionally jump to higher-energy configurations. In this case, the update rule is as follows: as before, if a change of state decreases the total energy, we apply that change: <d-math>\sigma_i \rightarrow -\sigma_i</d-math>. However, if a change increases the energy, i.e., if <d-math>\Delta E_i \geq 0</d-math>, instead of leaving the particle's state unchanged, we now flip it with probability <d-math>p = \exp(-1/T \Delta E_i) </d-math>. Note that <d-math>p\in [0, 1]</d-math>, since <d-math>\Delta E_i\geq 0</d-math>. Physically, these jumps to higher-energy states mimic the random thermal fluctuations arising from exchanging energy with an environment at finite temperature. </p>

<p>
 The sampling algorithm we have described above is in fact a specific instance of the Metropolis-Hastings algorithm []. One possible improvement to this approach is to consider models where the local update rule works better at finding low-energy configurations. One of the issues is that, since the change in energy <d-math>\Delta E_i = -2\sigma_i(b_i+\sum_j w_{ij}\sigma_j)</d-math> for particle <d-math>i</d-math> depends on the states of all other particles, each time a state is updated, it spreads out to all other particles, changing their update rules. For an RBM, however, this is not exactly the case. The energy change in a visible node, <d-math>\Delta E_i = -2v_i(b_i+\sum_j w_{ij}h_j)</d-math> does not depend on any of the other visible nodes, so when a visible node is flipped, other visible nodes are unaffected. This makes the local rule update more effective, since we can essentially treat the entire collection of visible nodes as a single entity. A similar statement holds for updating hidden nodes when the visible ones are fixed. In fact, the lack of intralayer interactions in an RBM implies that the conditional probabilities <d-math>P(v|h)</d-math> and <d-math>P(h|v)</d-math> factorize: </p>
 <p>
 <d-math block>
  \begin{aligned}
  P(v|h) &= \prod_i P(v_i|h)\\
  P(h|v) &= \prod_j P(h_j|v).
  \end{aligned}
  </d-math>
</p>
<p>
Moreover, because of the independence between nodes in the same layer, the individual conditional probabilities can be calculated analytically, and are given by [] <b>(JM: Should double-check this)</b>:</p>
<p>
<d-math block>
  \begin{aligned}
  P(v_i=1|h) &= \frac{1}{1+e^{-\Delta E_i/T}}\\
  P(h_j=1|v) &= \frac{1}{1+e^{-\Delta E_j/T}}.
  \end{aligned}
</d-math>
</p>
<p>
Note that <d-math>P(v_i=-1|h)</d-math> and <d-math>P(h_j=-1|v)</d-math> <d-math>P(h_j=-1|v)</d-math> follow from normalization. This permits a new sampling strategy. Fixing the hidden nodes, we sample from the conditional distribution <d-math>P(v|h) = \prod_i P(v_i|h)</d-math> by independently sampling the state of each particle from its distribution <d-math>P(v_i|h)</d-math>. Afterwards, the visible nodes are fixed and the same method is applied to the hidden units. By repeating this process several times, the resulting states will be approximately sampled from the system's Boltzmann distribution. This algorithm is known as <em>Gibbs sampling</em>, and it is the method typically used in practice to sample RBMs []. 
</p>

<!-- Second Section  4  -->
  <a class="marker" href="#section-4" id="section-4"><span>Training</span></a>
  <h2 id="training">Training</h2>

<p>
Significant progress has been made so far: we have understood how probabilistic models can be built from physical systems at thermal equilibrium, we have identified useful architectures for these systems, and have developed algorithms to sample from their Boltzmann distributions. A final challenge remains: how can we train these systems to perform specific tasks? Training in this sense means identifying the parameters <d-math>b_i</d-math> and <d-math>w_{ij}</d-math> of the energy function that give rise to the desired probability distribution. Searching for inspiration in physics has so far proved fruitful, so let's try that again.
</p>

<p>
The identification of binary variables with physical spins, as was done above, is a common connection between energy-based models and physical systems. However, for illustrative purposes, let us consider a simple physical system which may be more familiar: a mass attached to a spring, which experiences a position-dependent force <d-math>F(y)= -k y</d-math>. If this mass is placed in a gravitational field, it will experience a constant external force <d-math>F_g = mg </d-math>, where <d-math>g</d-math> is the acceleration due to gravity. The mass is only in equilibrium at the precise position where these two forces balance, i.e., when <d-math>F(y)+ F_g = 0</d-math>. Now suppose we have a simple model with energy-function <d-math>E(x) = \theta f(x)</d-math>. As discussed previously, the expectation value <d-math> f(x) \rangle </d-math> is a sufficient statistic of the Boltzmann distribution <d-math> P(x)=\frac{1}{Z}\exp[-E(x)/T]. </d-math> Knowing this expectation uniquely fixes the parameters <d-math> \theta</d-math> and therefore also the distribution itself. Now suppose that our goal is to train an energy-based model to reproduce the statistics of a dataset, specified as a set of configurations
<d-math>(x^{(1)}, x^{(2)}, \ldots, x^{(N)})</d-math>. Training the model is equivalent to identifying the parameter <d-math>\theta</d-math> such that the sufficient statistics of the model coincide with those of the data, i.e., <d-math> \langle f(x) \rangle_{\text{model}} = \langle f(x) \rangle_{\text{data}}</d-math>. Since the expectation over the model distribution depends on <d-math>\theta</d-math>, we can write <d-math> \langle f(x) \rangle_{\text{model}} = -F(\theta) </d-math>, whereas the expectation over data is a constant, <d-math> \langle f(x) \rangle_{\text{data}} = F_g </d-math>. Interpreting these as forces acting in opposite directions, and the parameter <d-math>\theta</d-math> as a position, we conclude that the model is trained when the position <d-math>\theta</d-math> is such that the forces are in equilibrium: <d-math>F(\theta)+F_g=0</d-math>. 
</p>

<p>
If forces are out of equilibrium, for instance if the pull of gravity outweighs the restoring force of the spring, objects will accelerate and change position. For an object starting at rest, the displacement due to an inbalance of forces is 
  <d-math block> 
    \theta \rightarrow \theta + \eta(\langle f(x) \rangle_{\text{data}}-\langle f(x) \rangle_{\text{model}}),
  </d-math>
where <d-math>\eta>0</d-math> is a constant that depends on the object's mass and the time for which the forces act on the object, which we assume to be small. The first fictitious force, <d-math>\langle f(x) \rangle_{\text{data}}</d-math>, can be thought of as an external force provided by an outside system, like the Earth's gravitational field. In this case, the external system is actually a set of training data. These data provide a constant downward "pull" towards preferred configurations which are exemplified in the dataset. 
The second fictitious force,  <d-math>\langle f(x) \rangle_{\text{model}}</d-math>, represents the system's natural preference for certain configurations. This provides a certain kind of internal "lift", working against the downward pull of the training data. Crucially, in the presence of two competing forces, the resulting displacement causes an object to move to a position that reduces the inbalance of forces. For example, if <d-math> F_g> ky </d-math> in our previous example, the spring is pulled downwards to a new position <d-math>y'>y</d-math> that increases the force due the spring. Overall, by repeatedly applying the update rule above for sufficiently small step sizes, we can find a parameter value that balances the two ficticious forces, leading to a trained model.
</p>


  <div class="row">
  <div class="column">
  <p class="slider-label-text">Training progress</p>
  <p id="temperature_slider" class="slider-label-number"></p>
    <input id="temp_slider_id" type="range" oninput="slider_fct_image_energies(this.value)" min="0" max="100" step="1.0">
  </div>
    <div class="doublecolumn">
    <p class="figure-text">add some text here</p>
    <figure style = "width:700px; height:500px; display:block; margin-left:auto; margin-right:auto; position:relative" id = "image_energies">
  <div id = "image_energies_id" style="position:absolute; left:0px; top:0px"></div>
  </figure>
  </div>
  </div>
  <script type = "text/javascript" src = "image_energies_script_new.js" ></script>
  <div class="triplecolumn"><p class="figure-text"><b>The purpose of training </b>is to find the model parameters that make the wanted configurations low energy. The model parameters are initiallized randomly and therefore the configuration's energies are also random. During the training we want to minimize the energies of the images we want to learn where at the same time we maximize the energies of configurations we don't want. This figure illustrates the evolution of energies over the training progress.</p></div>

<!-- Second Section  4.1  -->
  <a class="marker" href="#section-4.1" id="section-4.1"><span>Hopfield networks: training at zero temperature</span></a>
  <h3 id="hopfield-networks-training">Hopfield networks: training at zero temperature</h3>

  <p>The training procedure is a search for the parameters of the system's energy function which maximize the entropy and fulfil the constraints: in energy-based models, the procedure is nothing else than minimizing the energies of wanted configurations and avoiding to have energy minima for unwanted configurations. If we consider a Hopfield model the constraints are given by the expectation values 
<d-math>\langle \sigma_i \sigma_j \rangle </d-math>, <d-math>\langle \sigma_i \rangle</d-math> and we want to find the coupling parameters <d-math>w_{i,j}</d-math> and the local fields <d-math>h_i</d-math> of the energy function. To learn these system parameters we slowly change the parameters of the system until the expectation values of the model get closer of the expectation values of the data, leading to the memorization of the observed patterns.</p>

  <p>The training of a Hopfield network is deterministic and we update the weight matrix according to the Hebbian learning rule <d-cite> </d-cite> which is simply the outer product of the <d-math>n</d-math> input vectors <d-math>\{ \vec{\sigma}^{\alpha}\}_{\alpha}^n</d-math> that have to be memorised. Therefore the weights <d-math>W = \sum_{\alpha}^n( (\vec{\sigma}^{\alpha})^T \vec{\sigma}^{\alpha} - \mathbb{1}) </d-math>, which can be written as an update rule <d-math>w_{i,j} \rightarrow \sum_{\alpha}^n \sigma_i^{\alpha} \sigma_j^{\alpha}, \forall~i \neq j</d-math> , the subtraction of the identity matrix takes care that the nodes are not connected with themselves. The average over all the data instances <d-math>\alpha</d-math> is also often written as <d-math>\langle \sigma_i \sigma_j \rangle_{\text{Data}}</d-math>. This weight matrix leads to a energy landscape where each training vector is exactly a local minimum. And if we feed a slight variation of one of the input vectors into the network, the update rule will make them converge to the configuration that is associated with the closest energy minimum. The memory capacity of Hopfield networks is very limited and the more data we want to memorize, the higher is the chance to get so called spurious minima<d-footnote> Hebbian learning from page 354, <a href="http://page.mi.fu-berlin.de/rojas/neural/chapter/K13.pdf">http://page.mi.fu-berlin.de/rojas/neural/chapter/K13.pdf</a></d-footnote>. These are local energy minima which minimize the energy for configurations that are not part of the training and therefore will lead to wrong memories</p>

  <p>In <d-cite key="hopfield1983unlearning"></d-cite> Hopfield studied the effect of “unlearning” on the performance of Hopfield networks. They found that "unlearning" can help to get rid of supurous minima and therefore has a stabilizing effect on the memory of such a network. For unlearning, we expand the update rule <d-math>w_{i,j} \rightarrow \langle \sigma_i \sigma_j \rangle_{\text{Data}}</d-math> to <d-math>w_{i,j} \rightarrow \langle \sigma_i \sigma_j \rangle_{\text{Data}} - \epsilon \langle \sigma_i' \sigma_j' \rangle</d-math>. To obtain <d-math>\vec{\sigma}'</d-math>, the network is initialized in a random configuration <d-math>\vec{\sigma}</d-math> and the nodes are updated according to the update rule Eq. <d-footnote>Hopfield update rule <d-math> \sigma_{i}\rightarrow \left\{{\begin{array}{ll}+1~{\text{if }}\sum _{{j}}{w_{{ij}}\sigma_{j}}\geq h _{i},\\-1~{\text{otherwise,}}\end{array}}\right.</d-math></d-footnote> until the network equilibrates to <d-math>\vec{\sigma}'</d-math>. Therefore the configuration <d-math>\vec{\sigma}'</d-math> is a local minimum of the energy landscape and the term <d-math>- \epsilon \langle \sigma_i' \sigma_j' \rangle</d-math> increases the energy of this minimum by a small factor <d-math>\epsilon<1</d-math>. This plays against the first term of the update rule <d-math>\langle \sigma_i \sigma_j \rangle_{\text{Data}}</d-math> which minimizes the energies of the data inputs. The interplay of these two terms decreases the occurence of spurous minima. In the training of Boltzmann machines, similar terms appear, but they are often referred to as the positive and the negative phase.</p>

  <div class="row">
  <div class="triplecolumn">
    <input id="learn_button_id" type="button" value="Learning step" onclick="learn_phase()">
    <input id="learn_button_id" type="button" value="Unlearning step" onclick="unlearn_phase()">
    <input id="learn_button_id" type="button" value="Reinitialize" onclick="reinitialize_phase()">
  </div>
  <div class="triplecolumn">
    <figure style = "width:100%; height:400px; display:block; margin-left:auto; margin-right:auto; position:relative" id = "energy_landscape">
  <div id = "energy_landscape_figure_id" style="width:100%, height:100%, position:absolute; left:0px; top:0px"></div>
  </figure>
  <div class="triplecolumn">
	  <p class ="figure-text"><b>Learning and Unlearning: </b> A randomly initialized spin system has a energy landscape with many different local minima, which in physics is often referred to as the spinglass phase <d-cite> </d-cite>. Learning a certain configuration (red dots) in energy based models means we need to decrease its energy. But only by learning a configuration we do not get rid of spurious minima that contain unwanted configuration (yellow). They have to be unlearned.</p>
  </div> 
  <script type = "text/javascript" src = "energy_landscape.js" ></script>
  </div>
  </div>

<!-- Second Section  4.2  -->
  <a class="marker" href="#section-4.2" id="section-4.2"><span>Boltzmann machines: training at finite temperatures</span></a>
  <h3 id="the-ising-model-in-finite-temperature">Boltzmann machines: training at finite temperatures</h3>

  <p> If we set a finite temperature in an energy-based model, say <d-math>T=1</d-math><d-footnote>The actual value does not matter so much, since it can be absorbed in the weights of the model.</d-footnote>, it will no longer be deterministic and all the configurations can occur with a certain probability.
  We will show that as long as hidden units are not available, it is hard or even impossible to learn more complex configurations. There are several simple examples of datasets that are not learnable by a finite temperature Ising model without hidden units. One of them is the logical XOR gate that has the configurations (-1-1-1, -111, 1-11, 11-1). (ADD REF <d-footnote> Hebbian learning from page 354, <a href="http://page.mi.fu-berlin.de/rojas/neural/chapter/K13.pdf">http://page.mi.fu-berlin.de/rojas/neural/chapter/K13.pdf</a></d-footnote>
  It is not possible to make these four configurations low energy, while all other configurations are at high energy. To avoid this problem one can add a "dummy" spin that can be in an arbitrary state, which we simply do not consider as a result. The states (-1-1-11, -1111, 1-111, 111-1) are learnable and if we consider the first 3 spins our "data" we learned an XOR gate.
  </p>

  <p> In the figure below is a fully functional Ising model with <d-math>T=1 </d-math>, where we can add hidden nodes and also make it restricted. Try to make the "Bars and Stripes" images maximally likely by adjusting the weights and biases. You will see that this task is impossible if you don't have hidden units.</p>

  <div class="row">
  <div class="column">
  <p id="weight_slider_text" class="slider-label-text">Weight</p>
  <p id="weight_slider_value" class="slider-label-number"></p>
    <input id="weight_slider_id" value=0 type="range" onchange="slider_fct_RBM(this.value,'')" min="-2" max="2" step="0.01">
  <p id="bias_slider_text" class="slider-label-text">Bias</p>
  <p id="bias_slider_value" class="slider-label-number" width="50%"></p>
    <input id="bias_slider_id" value=0 type="range" oninput="slider_bias_just_text(this.value,'')" onchange="slider_bias_fct_RBM(this.value,'')" min="-2" max="2" step="0.01">
  <div>
  <input type="checkbox" onclick="change_layout_hidden('')" id="hidden_check" name="hidden_check"
         checked>
  <label for="hidden_check">Allow hidden units</label>
  </div>
  <div>
  <input type="checkbox" onclick="change_layout_restricted('')" id="restricted_check" name="restricted_check">
  <label for="restricted_check">Make it restricted</label>
  </div>
  </div>
  <div class="doublecolumn">
    <figure style = "width:100%; height:320px; display:block; margin-left:auto; margin-right:auto; position:relative" id = "RBM_complete">
  <div id = "RBM_complete_id" style="position:absolute; left:0px; top:0px"></div>
  </figure>
  <script type = "text/javascript" src = "RBM_complete_new.js" ></script>
  </div>
  </div>
  <div class="caption-triplecolumn"><p class="figure-text"> Try to make the "Bars and Stripes" configurations maximally likely.

 <div class="row">
  <div class="column">
  <p id="weight_slider_text_XOR" class="slider-label-text">Weight</p>
  <p id="weight_slider_value_XOR" class="slider-label-number"></p>
    <input id="weight_slider_id_XOR" value=0 type="range" onchange="slider_fct_RBM(this.value,'_XOR')" min="-2" max="2" step="0.01">
  <p id="bias_slider_text_XOR" class="slider-label-text">Bias</p>
  <p id="bias_slider_value_XOR" class="slider-label-number" width="50%"></p>
    <input id="bias_slider_id_XOR" value=0 type="range" oninput="slider_bias_just_text(this.value,'_XOR')" onchange="slider_bias_fct_RBM(this.value,'_XOR')" min="-2" max="2" step="0.01">
  <div>
  <input type="checkbox" onclick="change_layout_hidden('_XOR')" id="hidden_check_XOR" name="hidden_check_XOR"
         checked>
  <label for="hidden_check">Allow hidden units</label>
  </div>
  <div>
  <input type="checkbox" onclick="change_layout_restricted('_XOR')" id="restricted_check_XOR" name="restricted_check_XOR">
  <label for="restricted_check">Make it restricted</label>
  </div>
  </div>
  <div class="doublecolumn">
    <figure style = "width:100%; height:320px; display:block; margin-left:auto; margin-right:auto; position:relative" id = "RBM_complete_XOR">
  <div id = "RBM_complete_id_XOR" style="position:absolute; left:0px; top:0px"></div>
  </figure>
  <script type = "text/javascript" src = "RBM_complete_XOR.js" ></script>
  </div>
  </div>
  <div class="caption-triplecolumn"><p class="figure-text"> Try to make the "Bars and Stripes" configurations maximally likely.
  For this you have to adjust the weights and biases by clicking on the conections and the biases and adjust them with the slider.
  The color of the nodes indicates in which direction the spins are. This can help you to find the weights for a certain configurations and make its energy high or low. Remember that the wanted configurations should be low energy. And all the others should be higher energy. A way to find the solution for this task is to set the spins of the model to a B&S configuration and make its energy as small as possible. Then change to another B&S configuration and repeat. You will figure out eventually how you "learn" the weights. If you want to have a working solution, click the solution button.</p></div>
	  
For this you have to adjust the weights and biases by clicking on the conections and the biases and adjust them with the slider.
  The color of the nodes indicates in which direction the spins are. This can help you to find the weights for a certain configurations and make its energy high or low. Remember that the wanted configurations should be low energy. And all the others should be higher energy. A way to find the solution for this task is to set the spins of the model to a B&S configuration and make its energy as small as possible. Then change to another B&S configuration and repeat. You will figure out eventually how you "learn" the weights. If you want to have a working solution, click the solution button.</p></div>

  <p>More complex target distribution cannot be approximated without hidden nodes. To only use a Ising system to model data, where every spin represents a data point, will not be sufficient. A much more expressive model is the Boltzmann machine, where we start to distinguish between visible and hidden spin variables. On first glance there is no difference between the two models except the name of the nodes. But the crucial point is that only the visible units are used to represent data. The hidden units are only there to increase the space of possible configurations and their state will be ignored in the end. This way we can increase the expressivity of the model.</p>

  <p>Learning certain configurations means that the model parameters have to be adjusted in a way that the model distribution fits the target distribution. This task can be very demanding because all the parameters influence each other and a small change in the wrong direction can influence the probability distribution strongly. In real-world applications, each training step or parameter update only makes small adjustments.</p>

  <a class="marker" href="#section-4.3" id="section-4.3"><span>Contrastive divergence</span></a>
  <h3 id="r-bm-and-sampling">Contrastive divergence</h3>
  <p>As already discussed before, in physics equilibration occurs naturally and if we could implement a Boltzmann machine as a real system we could use the learning-unlearning approach to train the model, because it is actually possible to sample from it. A numerical implementation of a Boltzmann machine, on the other hand, would not allow us to sample from it. The problem is relatively simple: If a random initial configuration <d-math> \vec{\sigma} </d-math>is given, we have to update the spins to get to minimum energy. But if we update a single spin the probabilities for all the other spins to be in a certain direction might change drastically. To equilibrate such a system one would have to update the spins many times one after another and even then there is no gurantee to equilibrate.
  Therefore it is almost impossible to equilibrate to minimum energy if we numerically update spin after spin.</p>

  <p>To overcome this problem the restricted Boltzmann machine has been introduced. The idea here was, if we only allow couplings between the layers and not within the same layer, the probabilities of the single nodes of one layer become independent e.g. for the visible nodes <d-math>p(\vec{v}| \vec{h}) = \prod_i p(v_i | \vec{h}) </d-math>. This allows us to update a whole layer <d-math> \vec{v}</d-math> at a time only dependent on the other layer <d-math> \vec{h}</d-math> and vice versa. Furthermore, so far we assumed that we have access to the probability distribution of the energy-based model <d-math>p(x, \theta)</d-math> or for Boltzmann machines, <d-math>p(v,h, \theta)</d-math> and the data <d-math>p(v)</d-math>. In general, this is not true because the partition function <d-math>Z(\theta)</d-math> is not tractable for systems of the size <d-math>N>20</d-math>. Therefore to compare the statistics of the data with the statistics of the model we need to be able to approximate these distributions. For the data, this is relatively simple, since we can average over some data instances, for example over batches. On the other hand, to approximate the model distribution, we need configurations that come from the model itself. For a real physical system we therefore would set the parameters of the model, initialize some spin configuration and wait until it equilibrates. We would repeat this step and take many configurations and compare them to the data. Unfortunately we cannot simulate these equilibration dynamics on a computer because it is computationally intractable. What we can do is a Monte Carlo method called Gibbs sampling. To avoid this problem the graph of the Boltzmann machine can be made bipartite, which means that we separate the nodes in a visible and a hidden layer and don’t allow inter-layer connections. This architecture is called restricted Boltzmann machine. With this simple trick the conditional probabilities <d-math>p(\vec{v}|\vec{h})</d-math> and <d-math>p(\vec{h}|\vec{v})</d-math> marginalize and therefore we can sample each node of a layer independent of the other nodes of the same layer.</p>

  <p>Contrastive divergence (Cite Hinton) makes it possible to train RBMs efficiently. We would like to model the probability distribution of our data <d-math>p(x) </d-math> with a RBM which is nothing else than a parameterized probability function <d-math> p(x, \theta) </d-math>. Therefore during the training we want to make these two probability distributions as similar as possible. This similarity can be measured by the Kullback-Leibder divergence <d-math> KL(p(x)|p(x, \theta)) = \log(p(x)) \frac{p(x)}{p(x,\theta)} </d-math>. So in the end what we do is stochastic gradient descent with respect to the parameter <d-math> \theta </d-math>. If we calculate the derivatives, we find the update rule of the contrastive divergence algorithm algorithm:
  <d-math block> \Delta W_{i,j} = \langle v_i h_j\rangle_{\text{Data}} - \langle v_i h_j\rangle_{\text{Model}}</d-math>
  This is exactly the same update rule as already introduced by Hofield with the learning and the unlearning term. The only difference is that there are visible and  hidden units involved and that the same kind of units are not connected. Therefore terms like <d-math>\langle v_i v_j \rangle = 0</d-math>, but the intuition behind contrastive divergence is exactly the same. The learning term, <d-math> \langle v_i h_j\rangle_{\text{Data}}</d-math>, which for Boltzmann machines is mostly referred to as the positive phase decreases the energy of the configurations of the training data. The unlearning term <d-math> \langle v_i h_j\rangle_{\text{Model}}</d-math>, which is often referred to as the negative phase, increases the energy of all the configurations that are at equilibrium and therefore at low energy.
  </p>

<!-- Second Section  4.4  -->
  <a class="marker" href="#section-4.4" id="section-4.4"><span>Training and equilibrium</span></a>
  <h3 id="training-and-equilibrium">Training and equilibrium</h3>
  

  <div class="row">
  <div class="triplecolumn">
    <figure style = "width:100%; height:500px; display:block; margin-left:auto; margin-right:auto; position:relative" id = "architecture_Hopfield">
  <div id = "image_equilibration_id" style="position:absolute; left:0px; top:0px"></div>
  </figure>
  </div>
  <div class="triplecolumn">
    <p class="figure-text"> One  <input id="equilibrate_button_id" type="button" value="Equilibration step" onclick="equilibration_step_rbm()"> brings the damaged initial configuration closer to a low energy configuration. The hidden and the visible layers are updated one after another. </p><p class="figure-text"><b>Sampling through equilibration:</b> This figure shows a restricted Boltzmann machine, where the visible units are initialized with a partially damaged MNIST digit and the hidden units are initiallized all in the same direction. In an RBM, the equilibration is sequentially, where the hidden and the visible layer is sampled one after another dependend of the configuration of the other layer. The energy during the equilibration process will go to a lower value.</p>
  </div>
  </div>
  <script type = "text/javascript" src = "image_equilibration_script.js" ></script>

  <div class="triplecolumn"></div>

<!-- Second Section  4  -->
  <a class="marker" href="#section-5" id="section-5"><span>Conclusion</span></a>
  <h2 id="conclusion">Conclusion</h2>

  <p><b>PW: we should finish the conclusions with a paragraph on how these insights will help develop new energy-based models, e.g., new QBMs, continuous-valued stuff, what-not.</b></p>

</d-article>

<d-appendix>

  <h3>Contributions</h3>
  <p>Some text describing who did what.</p>
  <h3>Reviewers</h3>
  <p>Some text with links describing who reviewed the article.</p>
<d-footnote-list></d-footnote-list>
  <d-citation-list></d-citation-list>
  <!--  <d-bibliography src="bibliography.bib"></d-bibliography> -->
<d-bibliography>
    <script type="text/bibtex">
      @article{gregor2015draw,
        title={DRAW: A recurrent neural network for image generation},
        author={Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
        journal={arXiv preprint arXiv:1502.04623},
        year={2015},
        url ={https://arxiv.org/pdf/1502.04623.pdf}
      }
      @article{mercier2011humans,
        title={Why do humans reason? Arguments for an argumentative theory},
        author={Mercier, Hugo and Sperber, Dan},
        journal={Behavioral and brain sciences},
        volume={34},
        number={02},
        pages={57--74},
        year={2011},
        publisher={Cambridge Univ Press},
        doi={10.1017/S0140525X10000968}
      }
    </script>
  </d-bibliography>

  <distill-appendix> </distill-appendix>

</d-appendix>

<distill-footer></distill-footer>

</body>
